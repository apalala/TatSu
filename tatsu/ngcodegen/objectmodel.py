from collections import namedtuple

from .. import grammars, objectmodel
from ..mixins.indent import IndentPrintMixin
from ..util import safe_name, compress_seq
from ..walkers import NodeWalker


HEADER = """\
    #!/usr/bin/env python3

    # WARNING: CAVEAT UTILITOR
    #
    # This file was automatically generated by TatSu.
    #
    #    https://pypi.python.org/pypi/tatsu/
    #
    # Any changes you make to it will be overwritten the next time
    # the file is generated.

    from __future__ import annotations

    from typing import Any
    from dataclasses import dataclass

    from tatsu.semantics import ModelBuilderSemantics
    {base_type_import}


    @dataclass(eq=False)
    class {name}ModelBase({base_type}):
        pass


    class {name}ModelBuilderSemantics(ModelBuilderSemantics):
        def __init__(self, context=None, types=None):
            types = [
                t for t in globals().values()
                if type(t) is type and issubclass(t, {name}ModelBase)
            ] + (types or [])
            super().__init__(context=context, types=types)
"""


BaseClassSpec = namedtuple('TypeSpec', ['class_name', 'base'])


def modelgen(model: grammars.Model, parser_name: str = '', base_type: type = objectmodel.Node) -> str:
    generator = PythonModelGenerator(parser_name=parser_name, base_type=base_type)
    return generator.generate_model(model)


class PythonModelGenerator(IndentPrintMixin):

    def __init__(self, parser_name: str = '', base_type: type = objectmodel.Node):
        super().__init__()
        self.base_type = base_type
        self.parser_name = parser_name or None

    def generate_model(self, grammar: grammars.Grammar):
        base_type_qual = self.base_type.__module__
        base_type_import = f'from {self.base_type.__module__} import {self.base_type.__name__.split('.')[-1]}'

        self.parser_name = self.parser_name or grammar.name
        self.print(
            HEADER.format(
                name=self.parser_name,
                base_type=self.base_type.__name__,
                base_type_import=base_type_import,
            )
        )
        self.print()
        self.print()

        rule_index = {rule.name: rule for rule in grammar.rules}
        rule_specs = {
            rule.name: self._base_class_specs(rule)
            for rule in grammar.rules
        }

        model_classes = {s.class_name for spec in rule_specs.values() for s in spec}
        base_classes = {s.base for spec in rule_specs.values() for s in spec}
        base_classes -= model_classes

        for base_name in base_classes:
            if base_name in rule_specs:
                self._gen_base_class(rule_specs[base_name])

        for model_name, rule in rule_index.items():
            if model_name in rule_index:
                self._gen_rule_class(
                    rule,
                    rule_specs[model_name],
                )

        return self.printed_text()

    def _gen_base_class(self, spec: BaseClassSpec):
        self.print()
        self.print()
        if spec.base:
            self.print(f'class {spec.class_name}({spec.base}):')
        else:
            self.print(f'class {spec.class_name}:')
        with self.indent():
            self.print('pass')

    def _gen_rule_class(self, rule: grammars.Rule, specs: list[BaseClassSpec]):
        if not specs:
            return
        spec = specs[0]
        arguments = sorted({safe_name(d) for d, _ in compress_seq(rule.defines())})

        self.print()
        self.print()
        self.print('@dataclass(eq=False)')
        self.print(f'class {spec.class_name}({spec.base}):')
        with self.indent():
            if not arguments:
                self.print('pass')
            for arg in arguments:
                self.print(f'{arg}: Any = None')

    def walk_Rule(self, rule: grammars.Rule):
        specs = self._base_class_specs(rule)
        if not specs:
            return

        arguments = sorted({safe_name(d) for d, _ in compress_seq(rule.defines())})

        self.print()
        self.print()

        node_spec = specs[0]
        base_specs = list(reversed(specs[1:]))
        base = base_specs and base_specs[0] or f'{self.parser_name}ModelBase'
        self.print(f'class {node_spec.class_name}({base}):')

        with self.indent():
            if not arguments:
                self.print('pass')
            for arg in arguments:
                self.print(f'{arg}: Any = None')

    def _base_class_specs(self, rule: grammars.Rule) -> BaseClassSpec:
        if not rule.params:
            return ()

        spec = rule.params[0].split('::')
        class_names = [safe_name(n) for n in spec] + [f'{self.parser_name}ModelBase']
        return tuple(
            BaseClassSpec(class_name, class_names[i + 1])
            for i, class_name in enumerate(class_names[:-1])
        )
